{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os   \n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARENT_DIR = os.path.dirname(os.getcwd())\n",
    "src_path = os.path.join(PARENT_DIR, 'src')\n",
    "sys.path.append(src_path)\n",
    "\n",
    "from gpt import GPT\n",
    "from tokenizer import Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = GPT()\n",
    "tokenizer = Tokenize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311\n"
     ]
    }
   ],
   "source": [
    "PARENT_PARENT_DIR = os.path.dirname(PARENT_DIR)\n",
    "REDCODE_DIR = os.path.join(PARENT_PARENT_DIR, 'REDCODER')\n",
    "files = glob.glob(os.path.join(REDCODE_DIR, '*/**/***'))\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# english_translated_text = ''\n",
    "# with open(files[20], 'r', encoding='utf-8', errors='ignore') as file:\n",
    "#     content = file.read()\n",
    "#     english_translated_text = gpt.translate_code(content)\n",
    "#     print(english_translated_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[791, 2728, 2082, 374, 264, 13325, 8292, 315, 52818, 52, 320, 33, 50923, 40388, 9636, 56065, 8, 323, 11113, 7826, 877, 52, 11, 902, 527, 17150, 369, 38663, 279, 4367, 315, 5780, 14807, 16674, 13, 578, 2082, 5764, 5865, 369, 25213, 308, 12, 51870, 11, 38714, 52818, 52, 12483, 11, 323, 19486, 63061, 12823, 439, 33740, 304, 279, 5684, 555, 49335, 30237, 365, 8732, 323, 66620, 98541, 507, 331, 320, 19924, 1753, 220, 1049, 19, 570, 578, 1925, 734, 1595, 28806, 71813, 84, 63, 5097, 5905, 323, 14807, 8533, 64, 439, 1988, 323, 4780, 279, 52818, 52, 5573, 11, 308, 12, 1549, 5956, 6948, 11, 53584, 3152, 315, 308, 12, 1549, 5956, 6948, 11, 323, 5395, 85, 488, 16750, 13, 23212, 11, 1070, 596, 264, 13438, 734, 92721, 901, 84, 63, 902, 5097, 264, 5905, 11914, 323, 264, 25548, 11914, 439, 1988, 11, 323, 4780, 279, 52818, 52, 5573, 369, 430, 4040, 6857, 315, 23719, 13, 578, 2082, 1101, 5764, 264, 5842, 323, 45477, 311, 14158, 279, 3268, 323, 20746, 5552, 311, 279, 8292, 13]\n"
     ]
    }
   ],
   "source": [
    "english_translated_text = \"The given code is a Python implementation of BLEU (Bilingual Evaluation Understudy) and smooth-BLEU, which are metrics for evaluating the quality of machine translation outputs. The code includes functions for computing n-grams, calculating BLEU scores, and applying smoothing techniques as outlined in the paper by Chin-Yew Lin and Franz Josef Och (COLING 2004). The main function `compute_bleu` takes reference and translation corpora as input and returns the BLEU score, n-gram precisions, geometric mean of n-gram precisions, and brevity penalty. Additionally, there's a helper function `_bleu` which takes a reference sentence and a translated sentence as input, and returns the BLEU score for that particular pair of sentences. The code also includes a license and citation to specify the rights and credits related to the implementation.\"\n",
    "\n",
    "print(tokenizer.tokenizer(english_translated_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
